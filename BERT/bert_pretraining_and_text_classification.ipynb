{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jIANsrt7DIpn"
   },
   "source": [
    "## This notebook shows how to pretrain BERT and use it for text classification as a downstream task;\n",
    "* I used the compute resources from Google Colab (awesome lads)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0GYCrx05_Bgs",
    "outputId": "ff378c7e-613a-4030-f530-4d53931e3dbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==1.9 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9) (3.7.4.3)\n",
      "Requirement already satisfied: torchtext==0.10 in /usr/local/lib/python3.7/dist-packages (0.10.0)\n",
      "Requirement already satisfied: torch==1.9.0 in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (1.9.0+cu102)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (2.23.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (1.19.5)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (2.10)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch==1.9\n",
    "!pip install torchtext==0.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TsD8FOfy_Nj4"
   },
   "source": [
    "## Load necessary packages;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xdot5xzD-qOo",
    "outputId": "8a7afbb3-c8eb-4fd8-a9cc-1b6e78e56d0d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f02a11afe10>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bert_data_processing as bdp\n",
    "import torch\n",
    "from torch import nn\n",
    "import bert\n",
    "import transformer as tr\n",
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from torchtext.datasets import AG_NEWS\n",
    "mpl.style.use([\"ggplot\", \"dark_background\"])\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qTDewP-2_XXm"
   },
   "source": [
    "## Load the training part of the AG_NEWS dataset so that I pretrain BERT on it;\n",
    "* Note that the `max_len_consider` parameter is the maximum length of half a sentence, since for the Next Sentence Prediction pretraining task I basically split each sentence in two halves to mimic the sequential format;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "O9-zxrx1_KOw"
   },
   "outputs": [],
   "source": [
    "batch_size, max_len_consider = 256, 50\n",
    "loader, vocab = bdp.get_ag_news_loader_and_vocab(batch_size, max_len_consider, directory=\"../data\", vocab_min_freq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UjVjPOkd_zm4"
   },
   "source": [
    "### Take a look at the format:\n",
    "* Indexes of tokens;\n",
    "* Segment indexes;\n",
    "* Last index of seq to consider (i.e. don't consider pads);\n",
    "* Indexes of masks (i.e. masked by <mask\\> token, the original token or randomly sampled token);\n",
    "* Masked-Language-Model weights - since we are padding only calculate loss for actual masks and not pads;\n",
    "* The Next Sentence Prediction label (second sequence follows first or not);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IcTSUujj_jwn",
    "outputId": "ec7aa430-7267-44ff-ef22-8c62a354dddd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([    3,   392,   330,  1538,     2,   103,    58,     5,   810,     2,\n",
      "           27,     4,     0,   392,  1940, 10181,  3277,     8,     2,    38,\n",
      "         3914,   744,   296,     4,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1,\n",
      "            1,     1,     1,     1,     1,     1,     1,     1,     1,     1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0]), tensor(24.), tensor([ 4,  9, 18,  0,  0,  0,  0,  0]), tensor([1., 1., 1., 0., 0., 0., 0., 0.]), tensor([14290,    27,     0,     0,     0,     0,     0,     0]), tensor(1))\n"
     ]
    }
   ],
   "source": [
    "print(loader.dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOCkLL7CBD8m",
    "outputId": "fdf5cb3c-4be4-47c6-b1fc-30672752e24d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<cls>', 'wall', 'st', 'bears', '<mask>', 'back', 'into', 'the', 'black', '<mask>', 'reuters', '<sep>', '<unk>', 'wall', 'streets', 'dwindling', 'band', 'of', '<mask>', 'are', 'seeing', 'green', 'again', '<sep>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(vocab.convert_to_token(loader.dataset[0][0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yCVLbHiWBOui"
   },
   "source": [
    "### Get losses for MLM and NSP tasks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GBmfs0AXBL2w"
   },
   "outputs": [],
   "source": [
    "loss_mlm = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "loss_nsp = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-JOuL-dBXnl"
   },
   "source": [
    "### Instantiate BERT model;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BGNZHLSVBVPu"
   },
   "outputs": [],
   "source": [
    "vocab_size, hidden_dim, ffn_hidden, num_heads = len(vocab), 128, 256, 4\n",
    "norm_dim, ffn_input, num_layers, dropout, with_bias = [128], 128, 4, 0.2, True\n",
    "\n",
    "bert_model = bert.BertModel(hidden_dim, hidden_dim, hidden_dim, hidden_dim, num_heads,\n",
    "                            norm_dim, ffn_input, ffn_hidden, num_layers, vocab_size, pos_encoding_size=1000,\n",
    "                            mlm_input=hidden_dim, mlm_hiddens=2*hidden_dim, nsp_input=hidden_dim,\n",
    "                            nsp_hidden=2*hidden_dim, dropout=dropout, with_bias=with_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5wWUK79BwLN"
   },
   "source": [
    "### Decide on device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uo6FUajLBrEJ",
    "outputId": "4a915045-ea78-4ed9-bd96-295008662129"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be using cuda.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"I will be using {device}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LgStF8LKB7M6"
   },
   "source": [
    "### Move model to device;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvgQnt9rB4_2",
    "outputId": "2b77a45f-0027-40a6-c718-20f47a681f79"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (encoder): BertEncoder(\n",
       "    (word_embeds): Embedding(26320, 128)\n",
       "    (segment_embeds): Embedding(2, 128)\n",
       "    (encoders): Sequential(\n",
       "      (encoder_block_0): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_1): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_2): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_3): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlm): MLM(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=26320, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (nsp): NSP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWnlwS2HCFC8"
   },
   "source": [
    "### Get optimiser for the pretraining with scheduler to decrease learning rate by half after each epoch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "HtCLLORSB-xy"
   },
   "outputs": [],
   "source": [
    "adam_optim = torch.optim.Adam(bert_model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(adam_optim, step_size=1, gamma=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WcrptD9FCRhv"
   },
   "source": [
    "### Take a look at the output format of BERT;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S-wx5Qv9CNeT",
    "outputId": "cb4f2a9a-64b1-4778-960b-3fd85d034b0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of encoding: torch.Size([256, 50, 128]) --> (batch_size, seq_len, embed_size)\n",
      "shape of mlm_preds: torch.Size([256, 8, 26320]) --> (batch_size, num_masks, vocab_size)\n",
      "shape of nsp_preds: torch.Size([256, 2]) --> (batch_size, num_classes_to_predict)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "  bert_model.eval()\n",
    "  for (tokens, segments, attention_masks, masked_positions, weights_for_masks,\n",
    "        original_labels_for_masks, nsp_labels) in loader:\n",
    "      encodings, mlm_preds, nsp_preds = bert_model(tokens.to(device), segments.to(device), \n",
    "                                                    attention_masks.to(device), \n",
    "                                                    masked_positions.to(device))\n",
    "      break\n",
    "\n",
    "print(f\"shape of encoding: {encodings.shape} --> (batch_size, seq_len, embed_size)\")\n",
    "print(f\"shape of mlm_preds: {mlm_preds.shape} --> (batch_size, num_masks, vocab_size)\")\n",
    "print(f\"shape of nsp_preds: {nsp_preds.shape} --> (batch_size, num_classes_to_predict)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSH_UP1_DOw-"
   },
   "source": [
    "### Define how to combine losses from two pretrainig tasks;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "73t_rW02DTSd"
   },
   "outputs": [],
   "source": [
    "def loss_per_batch(bert_model, loss_mlm, loss_nsp, vocab_size, tokens, segments,\n",
    "                         attention_masks, masked_positions, weights_for_masks, \n",
    "                         original_labels_for_masks, nsp_labels):\n",
    "    \n",
    "    # effectively the forward pass;\n",
    "    encodings, mlm_preds, nsp_preds = bert_model(tokens, segments,\n",
    "                                          attention_masks, masked_positions)\n",
    "    # Now get loss from MLM task;\n",
    "    # it is important that the loss reduction is none, so that I can customize it a bit\n",
    "    # by multiplying by weights so that I don't count the loss from <pad> tokens\n",
    "    # when doing the MLM model;\n",
    "    mlm_loss = loss_mlm(mlm_preds.reshape(-1, vocab_size), \n",
    "                    original_labels_for_masks.reshape(-1)) * weights_for_masks.reshape(-1)\n",
    "    \n",
    "    # now I can average the MLM loss over the weights;\n",
    "    mlm_loss = mlm_loss.sum() / (weights_for_masks.sum() + 1e-9)\n",
    "    \n",
    "    # Now get the next sentence prediction loss;\n",
    "    # here this is the default reduction for loss_nsp, i.e. averaged;\n",
    "    nsp_loss = loss_nsp(nsp_preds, nsp_labels)\n",
    "    \n",
    "    # combine the two losses;\n",
    "    sum_of_losses = mlm_loss + nsp_loss\n",
    "    return mlm_loss, nsp_loss, sum_of_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l17yVDk9CiMx"
   },
   "source": [
    "### Define a training loop for one epoch;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "RLAfj3guCewa"
   },
   "outputs": [],
   "source": [
    "def train_loop(bert_model, loss_nsp, loss_mlm, optim, loader, vocab):\n",
    "  vocab_size = torch.tensor(len(vocab), device=device)\n",
    "  bert_model.to(device)\n",
    "  bert_model.train()\n",
    "  fifth = max(1, len(loader) // 5)\n",
    "  tot_loss_per_epoch = 0.\n",
    "  tot_mlm_loss_per_epoch = 0.\n",
    "  tot_nsp_loss_per_epoch = 0.\n",
    "  size = len(loader.dataset)\n",
    "\n",
    "  for batch, (tokens, segments, attention_masks, masked_positions, weights_for_masks,\n",
    "         original_labels_for_masks, nsp_labels) in enumerate(loader, start=1):\n",
    "        # forward pass on one batch plus calculating the loss(es);\n",
    "        mlm_loss, nsp_loss, sum_of_losses = loss_per_batch(bert_model, loss_mlm, loss_nsp,\n",
    "                                                          vocab_size, \n",
    "                                                           tokens.to(device), \n",
    "                                                           segments.to(device),\n",
    "                                                          attention_masks.to(device), \n",
    "                                                           masked_positions.to(device),\n",
    "                                                          weights_for_masks.to(device),\n",
    "                                                          original_labels_for_masks.to(device), \n",
    "                                                           nsp_labels.to(device))\n",
    "        if batch % fifth == 0:\n",
    "          print(f\"mlm_loss:  {mlm_loss:.5f}\\tnsp_loss:  {nsp_loss:.5f}\\tcombined_loss:  {sum_of_losses:.5f}\\tprogress:  {batch}/{len(loader)}\")\n",
    "        tot_loss_per_epoch += sum_of_losses.item() * len(nsp_labels)\n",
    "        tot_mlm_loss_per_epoch += mlm_loss.item() * len(nsp_labels)\n",
    "        tot_nsp_loss_per_epoch += nsp_loss.item() * len(nsp_labels)\n",
    "        # now for the backward pass;\n",
    "        optim.zero_grad()\n",
    "        sum_of_losses.backward()\n",
    "        optim.step()\n",
    "  print(f\"mlm_loss_per_epoch:  {tot_mlm_loss_per_epoch/size:.5f}\\tnsp_loss_per_epoch:  {tot_nsp_loss_per_epoch/size:.5f}\\tcombined_loss_per_epoch:  {tot_loss_per_epoch/size:.5f}\")\n",
    "  return tot_mlm_loss_per_epoch/size, tot_nsp_loss_per_epoch/size, tot_loss_per_epoch/size        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQWwwLTlFtHO"
   },
   "source": [
    "### Start the pretraining procedure;\n",
    "* The purpose here is to show that the current configuration \"trains\" since the loss falls;\n",
    "* Obviously the choice of training for only 5 epochs is arbitrary and it is possible that different hyperparameter configuration may yield better results;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "R5W1xl6VESSI"
   },
   "outputs": [],
   "source": [
    "best_loss_pre = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0i5KzehZFiZq",
    "outputId": "6353ad55-4af7-41f9-a21b-48c18ff8c91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "----------------------------------------\n",
      "mlm_loss:  7.77615\tnsp_loss:  0.68801\tcombined_loss:  8.46416\tprogress:  85/429\n",
      "mlm_loss:  7.63088\tnsp_loss:  0.68875\tcombined_loss:  8.31963\tprogress:  170/429\n",
      "mlm_loss:  7.60722\tnsp_loss:  0.70110\tcombined_loss:  8.30833\tprogress:  255/429\n",
      "mlm_loss:  7.46250\tnsp_loss:  0.67030\tcombined_loss:  8.13280\tprogress:  340/429\n",
      "mlm_loss:  7.37501\tnsp_loss:  0.67108\tcombined_loss:  8.04609\tprogress:  425/429\n",
      "mlm_loss_per_epoch:  7.64519\tnsp_loss_per_epoch:  0.68582\tcombined_loss_per_epoch:  8.33101\n",
      "last_lr: 0.00100\n",
      "\n",
      "Epoch 2:\n",
      "----------------------------------------\n",
      "mlm_loss:  7.41116\tnsp_loss:  0.65799\tcombined_loss:  8.06914\tprogress:  85/429\n",
      "mlm_loss:  7.43081\tnsp_loss:  0.65916\tcombined_loss:  8.08996\tprogress:  170/429\n",
      "mlm_loss:  7.22762\tnsp_loss:  0.63185\tcombined_loss:  7.85947\tprogress:  255/429\n",
      "mlm_loss:  7.18296\tnsp_loss:  0.63866\tcombined_loss:  7.82162\tprogress:  340/429\n",
      "mlm_loss:  7.22548\tnsp_loss:  0.60775\tcombined_loss:  7.83323\tprogress:  425/429\n",
      "mlm_loss_per_epoch:  7.35345\tnsp_loss_per_epoch:  0.65318\tcombined_loss_per_epoch:  8.00663\n",
      "last_lr: 0.00075\n",
      "\n",
      "Epoch 3:\n",
      "----------------------------------------\n",
      "mlm_loss:  7.23518\tnsp_loss:  0.66889\tcombined_loss:  7.90407\tprogress:  85/429\n",
      "mlm_loss:  7.07600\tnsp_loss:  0.61830\tcombined_loss:  7.69430\tprogress:  170/429\n",
      "mlm_loss:  7.22533\tnsp_loss:  0.63190\tcombined_loss:  7.85723\tprogress:  255/429\n",
      "mlm_loss:  7.06947\tnsp_loss:  0.64424\tcombined_loss:  7.71372\tprogress:  340/429\n",
      "mlm_loss:  7.07762\tnsp_loss:  0.63439\tcombined_loss:  7.71202\tprogress:  425/429\n",
      "mlm_loss_per_epoch:  7.17152\tnsp_loss_per_epoch:  0.64219\tcombined_loss_per_epoch:  7.81371\n",
      "last_lr: 0.00056\n",
      "\n",
      "Epoch 4:\n",
      "----------------------------------------\n",
      "mlm_loss:  6.95811\tnsp_loss:  0.62474\tcombined_loss:  7.58285\tprogress:  85/429\n",
      "mlm_loss:  6.98332\tnsp_loss:  0.62385\tcombined_loss:  7.60716\tprogress:  170/429\n",
      "mlm_loss:  6.95117\tnsp_loss:  0.59512\tcombined_loss:  7.54629\tprogress:  255/429\n",
      "mlm_loss:  6.90980\tnsp_loss:  0.60061\tcombined_loss:  7.51041\tprogress:  340/429\n",
      "mlm_loss:  6.71647\tnsp_loss:  0.62669\tcombined_loss:  7.34316\tprogress:  425/429\n",
      "mlm_loss_per_epoch:  6.98302\tnsp_loss_per_epoch:  0.62844\tcombined_loss_per_epoch:  7.61146\n",
      "last_lr: 0.00042\n",
      "\n",
      "Epoch 5:\n",
      "----------------------------------------\n",
      "mlm_loss:  6.86795\tnsp_loss:  0.59518\tcombined_loss:  7.46313\tprogress:  85/429\n",
      "mlm_loss:  6.99410\tnsp_loss:  0.57090\tcombined_loss:  7.56500\tprogress:  170/429\n",
      "mlm_loss:  6.72289\tnsp_loss:  0.65002\tcombined_loss:  7.37291\tprogress:  255/429\n",
      "mlm_loss:  6.78399\tnsp_loss:  0.62681\tcombined_loss:  7.41080\tprogress:  340/429\n",
      "mlm_loss:  6.74114\tnsp_loss:  0.58006\tcombined_loss:  7.32120\tprogress:  425/429\n",
      "mlm_loss_per_epoch:  6.80572\tnsp_loss_per_epoch:  0.60913\tcombined_loss_per_epoch:  7.41485\n",
      "last_lr: 0.00032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}:\\n----------------------------------------\")\n",
    "  mlm, nsp, combined = train_loop(bert_model, loss_nsp, loss_mlm, adam_optim, loader, vocab)\n",
    "  print(f\"last_lr: {scheduler.get_last_lr()[-1]:.5f}\\n\")\n",
    "  scheduler.step()\n",
    "  if best_loss_pre is None or combined < best_loss_pre:\n",
    "    best_loss_pre = combined\n",
    "    torch.save(bert_model.state_dict(), \"bert_pretrained.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fNAIgTe7L5m_"
   },
   "source": [
    "## Now doing the classification problem;\n",
    "* First, load the \"best\" pretrained BERT;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "1g9rwClWN9Oj"
   },
   "outputs": [],
   "source": [
    "vocab_size, hidden_dim, ffn_hidden, num_heads = len(vocab), 128, 256, 4\n",
    "norm_dim, ffn_input, num_layers, dropout, with_bias = [128], 128, 4, 0.2, True\n",
    "\n",
    "best_bert_pre = bert.BertModel(hidden_dim, hidden_dim, hidden_dim, hidden_dim, num_heads,\n",
    "                            norm_dim, ffn_input, ffn_hidden, num_layers, vocab_size, pos_encoding_size=1000,\n",
    "                            mlm_input=hidden_dim, mlm_hiddens=2*hidden_dim, nsp_input=hidden_dim,\n",
    "                            nsp_hidden=2*hidden_dim, dropout=dropout, with_bias=with_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K0eGrdsbOU1p",
    "outputId": "f0010efd-c545-4409-d625-232ad7042809"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bert_pre.load_state_dict(torch.load(\"bert_pretrained.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5hrURmkOe71",
    "outputId": "57a91b4f-88b1-4ba6-ece8-f2b94b140f45"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (encoder): BertEncoder(\n",
       "    (word_embeds): Embedding(26320, 128)\n",
       "    (segment_embeds): Embedding(2, 128)\n",
       "    (encoders): Sequential(\n",
       "      (encoder_block_0): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_1): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_2): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_block_3): EncoderBlock(\n",
       "        (attention): MHAttention(\n",
       "          (attention_pooling): LearnableDotProdAttention(\n",
       "            (dropout): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (W_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (W_o): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (add_norm1): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (ffn): EncBlockFFN(\n",
       "          (net): Sequential(\n",
       "            (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (add_norm2): AddNorm(\n",
       "          (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlm): MLM(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=26320, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (nsp): NSP(\n",
       "    (net): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=256, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_bert_pre.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iysZ5u3HMA8J"
   },
   "source": [
    "### Define classification head;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "8cnthj6XHLD4"
   },
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "  def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "    super(ClassificationHead, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "    self.ln1 = nn.LayerNorm([hidden_dim])\n",
    "    self.relu = nn.ReLU()\n",
    "    self.linear2 = nn.Linear(hidden_dim, output_dim)\n",
    "  \n",
    "  def forward(self, cls_token):\n",
    "    out = self.ln1(self.linear1(cls_token))\n",
    "    return self.linear2(self.relu(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLbW7LyYOs3B"
   },
   "source": [
    "### Prepare data for classification task for the AG_NEWS dataset;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "nuOG6NyHN9h2"
   },
   "outputs": [],
   "source": [
    "train_iter, test_iter = AG_NEWS(\"../data\", split=(\"train\", \"test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "h29WZCZLOyfd"
   },
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    return re.sub(\"[^A-Za-z\\s]+\", '', re.sub(\"\\\\\\\\\", ' ', text).strip()).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "kPKUTJqYPIfU"
   },
   "outputs": [],
   "source": [
    "# labels oddly start from 1 to 4, so subtract one to make them start from 0 to 3;\n",
    "tuple_list_train = [(clean_text(text), num_label-1) \n",
    "                    for num_label, text in train_iter]\n",
    "tuple_list_test = [(clean_text(text), num_label-1) \n",
    "                    for num_label, text in test_iter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNzvXk7X6Ac3"
   },
   "source": [
    "### Check out the distribution of sequence lengths in train set and test set, to pick a padding length;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "bE9Ngp9APtDv"
   },
   "outputs": [],
   "source": [
    "train_lens = [len(text.split()) for text, _ in tuple_list_train]\n",
    "test_lens = [len(text.split()) for text, _ in tuple_list_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "id": "8UPBscCBQbEh",
    "outputId": "bbe76754-e685-4f52-ea0e-557c8b2b074b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "ax.hist(np.array([train_lens, test_lens], dtype=\"object\"), color=[\"cyan\", \"magenta\"], label=[\"train\", \"test\"])\n",
    "ax.legend()\n",
    "ax.set_title(\"Distribution of lengths of sequences for train and test set\")\n",
    "ax.set_xlabel(\"length of sequence\")\n",
    "ax.set_ylabel(\"count of sequences\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWDWbeVWULZ7"
   },
   "source": [
    "### Seems len of 75 is ok for padding;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "6ivwAopKXHrU"
   },
   "outputs": [],
   "source": [
    "def get_tensors_from_strings(tuple_list, vocab, pad_len):\n",
    "  padded_text = []\n",
    "  all_segments = []\n",
    "  all_attention_masks = []\n",
    "  all_labels = []\n",
    "\n",
    "  for text, label in tuple_list:\n",
    "    tokenised = text.split()\n",
    "    # since we will add <cls> and <sep> per sequence;\n",
    "    if len(tokenised) + 2 <= pad_len and len(tokenised) > 0:\n",
    "      tokenised, segments = bert.get_tokens_and_segments(tokenised)\n",
    "      padded_text.append(\n",
    "          torch.tensor(vocab[tokenised] + [0] * (pad_len - len(tokenised)), dtype=torch.long))\n",
    "      all_segments.append(\n",
    "          torch.tensor(segments + [0] * (pad_len - len(tokenised)), dtype=torch.long))\n",
    "      all_attention_masks.append(torch.tensor(len(tokenised), dtype=torch.long))\n",
    "      all_labels.append(torch.tensor(label, dtype=torch.long))\n",
    "\n",
    "  return (padded_text, all_segments, \n",
    "          all_attention_masks, all_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qil2rSB17hP9"
   },
   "source": [
    "### Get Dataset objects;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "Jy9v46FoWY5A"
   },
   "outputs": [],
   "source": [
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, tuple_list, vocab, pad_len, **kwargs):\n",
    "    super(ClassificationDataset, self).__init__(**kwargs)\n",
    "    (self.padded_text, self.all_segments, \n",
    "     self.all_attention_masks, self.all_labels) = get_tensors_from_strings(\n",
    "         tuple_list, vocab, pad_len)\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.all_labels)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    return (self.padded_text[idx], self.all_segments[idx],\n",
    "            self.all_attention_masks[idx], self.all_labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "eDQj30bMcFj8"
   },
   "outputs": [],
   "source": [
    "train_dataset = ClassificationDataset(tuple_list_train, vocab, pad_len=75)\n",
    "test_dataset = ClassificationDataset(tuple_list_test, vocab, pad_len=75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wyFK7wc0d9-I",
    "outputId": "9f23ed8e-6294-4b4e-97b6-050ce511240c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of training dataset: 119192\n",
      "\n",
      "length of testing dataset: 7553\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"length of training dataset: {len(train_dataset)}\\n\")\n",
    "print(f\"length of testing dataset: {len(test_dataset)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orYzbdh17lLc"
   },
   "source": [
    "### Wrap DataLoader objects;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "pAKOzPyed2Rs"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZ2RLrKp7pYi"
   },
   "source": [
    "### Proceed with classification_loss;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "moTNN1QmePVs"
   },
   "outputs": [],
   "source": [
    "classification_loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TuMEXV7q7ulB"
   },
   "source": [
    "### Instantiate classification head object;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HN2d19q_71VK",
    "outputId": "2dffaea0-4249-4d0c-95a1-34125bdfed82"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassificationHead(\n",
       "  (linear1): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (ln1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (relu): ReLU()\n",
       "  (linear2): Linear(in_features=128, out_features=4, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# there are only 4 classes;\n",
    "head_input_dim, head_hidden_dim, head_output_dim, dropout = hidden_dim, hidden_dim, 4, 0.4\n",
    "classification_head = ClassificationHead(head_input_dim, head_hidden_dim, head_output_dim)\n",
    "classification_head.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TV5mT9VT8rm6"
   },
   "source": [
    "### Now get the optimiser that is going to optimise the parameters of the transformer and the classification head;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "QQo89H0d80tH"
   },
   "outputs": [],
   "source": [
    "combined_adam = torch.optim.Adam(itertools.chain(best_bert_pre.parameters(), classification_head.parameters()),\n",
    "                                 lr=1e-3)\n",
    "combined_scheduler = torch.optim.lr_scheduler.StepLR(combined_adam, step_size=1, gamma=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vjjg2VUZ9sTj"
   },
   "source": [
    "### Define training loop and test loop for the text classification task (for AG_NEWS);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "8yMubBgc9xyA"
   },
   "outputs": [],
   "source": [
    "def combined_train_loop(bert_model, classification_head, loss_fn, optim, train_loader):\n",
    "  tot_train_loss, fifth = 0., max(1, len(train_loader) // 5)\n",
    "  size = len(train_loader.dataset)\n",
    "  bert_model.train()\n",
    "  classification_head.train()\n",
    "  for batch, (padded_text, segments, attention_masks, labels) in enumerate(train_loader, start=1):\n",
    "    encodings, _, _ = bert_model(padded_text.to(device), segments.to(device), \n",
    "                                 attention_masks.to(device))\n",
    "    # classify from <cls> tokens;\n",
    "    preds = classification_head(encodings[:, 0, :])\n",
    "    loss = loss_fn(preds, labels.to(device))\n",
    "    if batch % fifth == 0:\n",
    "      print(f\"train_loss: {loss.item():.5f}\\tprogress: {batch}/{len(train_loader)}\")\n",
    "    tot_train_loss += loss.item() * len(labels)\n",
    "\n",
    "    # backward pass;\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "  print(f\"avg_train_loss: {tot_train_loss/size:.5f}\")\n",
    "  return tot_train_loss/size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "s4o2tR5m_d5u"
   },
   "outputs": [],
   "source": [
    "def combined_test_loop(bert_model, classification_head, loss_fn, test_loader):\n",
    "  correct, size = 0., len(test_loader.dataset)\n",
    "  tot_test_loss = 0.\n",
    "  bert_model.eval()\n",
    "  classification_head.eval()\n",
    "\n",
    "  with torch.no_grad():\n",
    "    for padded_text, segments, attention_masks, labels in test_loader:\n",
    "      encodings, _, _ = bert_model(padded_text.to(device), segments.to(device), \n",
    "                                 attention_masks.to(device))\n",
    "      # classify from <cls> tokens;\n",
    "      preds = classification_head(encodings[:, 0, :])\n",
    "      loss = loss_fn(preds, labels.to(device))\n",
    "      tot_test_loss += loss.item() * len(labels)\n",
    "      correct += (preds.argmax(1) == labels.to(device)).sum().item()\n",
    "    print(f\"avg_test_loss: {tot_test_loss/size:.5f}\\ttest_accuracy: {correct/size:.5f}\")\n",
    "    return tot_test_loss/size, correct/size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AGY57nI3Ai1g"
   },
   "source": [
    "### Train and evaluate;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "1SRV6BfjBUs6"
   },
   "outputs": [],
   "source": [
    "best_test_loss = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tEQdrhXqAwmg",
    "outputId": "cc2119ea-f7dd-423b-c4e5-ed65256938fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1:\n",
      "-----------------------------------\n",
      "train_loss: 0.65715\tprogress: 93/466\n",
      "train_loss: 0.53230\tprogress: 186/466\n",
      "train_loss: 0.50557\tprogress: 279/466\n",
      "train_loss: 0.45116\tprogress: 372/466\n",
      "train_loss: 0.47890\tprogress: 465/466\n",
      "avg_train_loss: 0.59113\n",
      "avg_test_loss: 0.43842\ttest_accuracy: 0.84258\n",
      "last_lr: 0.00100\n",
      "\n",
      "Epoch 2:\n",
      "-----------------------------------\n",
      "train_loss: 0.33530\tprogress: 93/466\n",
      "train_loss: 0.37243\tprogress: 186/466\n",
      "train_loss: 0.34626\tprogress: 279/466\n",
      "train_loss: 0.41908\tprogress: 372/466\n",
      "train_loss: 0.31255\tprogress: 465/466\n",
      "avg_train_loss: 0.40237\n",
      "avg_test_loss: 0.37242\ttest_accuracy: 0.87065\n",
      "last_lr: 0.00080\n",
      "\n",
      "Epoch 3:\n",
      "-----------------------------------\n",
      "train_loss: 0.23050\tprogress: 93/466\n",
      "train_loss: 0.27916\tprogress: 186/466\n",
      "train_loss: 0.28983\tprogress: 279/466\n",
      "train_loss: 0.36546\tprogress: 372/466\n",
      "train_loss: 0.24965\tprogress: 465/466\n",
      "avg_train_loss: 0.33241\n",
      "avg_test_loss: 0.32361\ttest_accuracy: 0.88839\n",
      "last_lr: 0.00064\n",
      "\n",
      "Epoch 4:\n",
      "-----------------------------------\n",
      "train_loss: 0.32795\tprogress: 93/466\n",
      "train_loss: 0.27278\tprogress: 186/466\n",
      "train_loss: 0.33349\tprogress: 279/466\n",
      "train_loss: 0.25433\tprogress: 372/466\n",
      "train_loss: 0.28136\tprogress: 465/466\n",
      "avg_train_loss: 0.28875\n",
      "avg_test_loss: 0.32060\ttest_accuracy: 0.89183\n",
      "last_lr: 0.00051\n",
      "\n",
      "Epoch 5:\n",
      "-----------------------------------\n",
      "train_loss: 0.23452\tprogress: 93/466\n",
      "train_loss: 0.23567\tprogress: 186/466\n",
      "train_loss: 0.30177\tprogress: 279/466\n",
      "train_loss: 0.24942\tprogress: 372/466\n",
      "train_loss: 0.23486\tprogress: 465/466\n",
      "avg_train_loss: 0.25899\n",
      "avg_test_loss: 0.29436\ttest_accuracy: 0.90097\n",
      "last_lr: 0.00041\n",
      "\n",
      "Epoch 6:\n",
      "-----------------------------------\n",
      "train_loss: 0.24952\tprogress: 93/466\n",
      "train_loss: 0.27947\tprogress: 186/466\n",
      "train_loss: 0.19566\tprogress: 279/466\n",
      "train_loss: 0.16630\tprogress: 372/466\n",
      "train_loss: 0.19136\tprogress: 465/466\n",
      "avg_train_loss: 0.23609\n",
      "avg_test_loss: 0.28794\ttest_accuracy: 0.90229\n",
      "last_lr: 0.00033\n",
      "\n",
      "Epoch 7:\n",
      "-----------------------------------\n",
      "train_loss: 0.23989\tprogress: 93/466\n",
      "train_loss: 0.23818\tprogress: 186/466\n",
      "train_loss: 0.18487\tprogress: 279/466\n",
      "train_loss: 0.22174\tprogress: 372/466\n",
      "train_loss: 0.23924\tprogress: 465/466\n",
      "avg_train_loss: 0.21613\n",
      "avg_test_loss: 0.29270\ttest_accuracy: 0.90335\n",
      "last_lr: 0.00026\n",
      "\n",
      "Epoch 8:\n",
      "-----------------------------------\n",
      "train_loss: 0.24633\tprogress: 93/466\n",
      "train_loss: 0.13350\tprogress: 186/466\n",
      "train_loss: 0.24557\tprogress: 279/466\n",
      "train_loss: 0.22211\tprogress: 372/466\n",
      "train_loss: 0.17228\tprogress: 465/466\n",
      "avg_train_loss: 0.19742\n",
      "avg_test_loss: 0.28549\ttest_accuracy: 0.90520\n",
      "last_lr: 0.00021\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 8\n",
    "for t in range(epochs):\n",
    "  print(f\"Epoch {t+1}:\\n-----------------------------------\")\n",
    "  train_loss = combined_train_loop(best_bert_pre, classification_head, \n",
    "                                   classification_loss, combined_adam, train_loader)\n",
    "  test_loss, test_accuracy = combined_test_loop(best_bert_pre, classification_head,\n",
    "                                                classification_loss, test_loader)\n",
    "  print(f\"last_lr: {combined_scheduler.get_last_lr()[-1]:.5f}\\n\")\n",
    "  combined_scheduler.step()\n",
    "  if best_test_loss is None or test_loss < best_test_loss:\n",
    "    torch.save(best_bert_pre.state_dict(), \"best_bert_classification.pt\")\n",
    "    torch.save(classification_head.state_dict(), \"best_classifier_head.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kB368YPcoeAn"
   },
   "source": [
    "### Summary:\n",
    "* So this ended up being a bit of a proof of concept, that this *from-scratch* model works. I reached **90%** accuracy on a balanced test_set with relatively low computational demands.\n",
    "* However, more importantly for myself was that my weird idea of splitting each sentence in halves to \"fool\" **BERT** to treat the halves as sentences for the Next Sentence Prediction pretraining task seems to have yielded good results.\n",
    "* This was an idea that intuitively made sense to me, but now there are also some empirical arguments in favour of it."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
